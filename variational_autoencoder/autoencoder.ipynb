{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, ReLU, BatchNormalization, Flatten, Dense, Reshape, Conv2DTranspose, Activation, Lambda\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import MeanSquaredError\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_reconstruction_loss(y_target, y_predicted):\n",
    "    error = y_target-y_predicted\n",
    "    reconstruction_loss = K.mean(K.square(error), axis=[1,2,3])\n",
    "    return reconstruction_loss\n",
    "\n",
    "def calculate_kl_loss(model):\n",
    "    \n",
    "    def _calculate_kl_loss(*args):\n",
    "        kl_loss = -0.5 * K.sum(1 + model.log_variance - K.square(model.mu) - K.exp(model.log_variance), axis=1)\n",
    "        return kl_loss\n",
    "    return _calculate_kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE:\n",
    "    \"\"\"\n",
    "    VAE represents a Deep Convolutiuonal variational autoencoder architecture with mirrored encoder and decoder components.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_shape, conv_filters, conv_kernels, conv_strides, latent_space_dim):\n",
    "        self.input_shape=input_shape # [width, height, channel] [28,28,1]\n",
    "        self.conv_filters=conv_filters # [2,4,8]\n",
    "        self.conv_kernels=conv_kernels # [3,5,3]\n",
    "        self.conv_strides=conv_strides # [1,2,2]\n",
    "        self.latent_space_dim=latent_space_dim\n",
    "        self.reconstruction_loss_weight=1000\n",
    "\n",
    "        self.encoder = None\n",
    "        self.decoder = None\n",
    "        self.model = None\n",
    "\n",
    "        self._num_conv_layers = len(conv_filters)\n",
    "\n",
    "        self._build() #building encoder decoder model\n",
    "\n",
    "    def summary(self):\n",
    "        self.encoder.summary()\n",
    "        self.decoder.summary()\n",
    "        self.model.summary()\n",
    "    \n",
    "    def compile(self, learning_rate=0.0001):\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "        self.model.compile(optimizer=optimizer, \n",
    "                            loss=self._calculate_combined_loss,\n",
    "                            metrics=[_calculate_reconstruction_loss, calculate_kl_loss(self)])\n",
    "\n",
    "\n",
    "    \n",
    "    def train(self, x_train, batch_size, num_epochs):\n",
    "        # input should be the same as the output in the params,\n",
    "        # we are trying to reconstruct the output and have it as similar as possible to the input\n",
    "        self.model.fit(x_train, \n",
    "                        x_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=num_epochs,\n",
    "                        shuffle=True)\n",
    "    def save(self, save_folder=\".\"):\n",
    "        self._create_folder_if_doesnt_exist(save_folder)\n",
    "        self._save_parameters(save_folder)\n",
    "        self._save_weights(save_folder)\n",
    "\n",
    "    def load_weights(self, weights_path):\n",
    "        self.model.load_weights(weights_path)\n",
    "    \n",
    "    def reconstruct(self, images):\n",
    "        latent_representations = self.encoder.predict(images)\n",
    "        reconstructed_images = self.decoder.predict(latent_representations)\n",
    "        return reconstructed_images, latent_representations\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls,save_folder=\".\"):\n",
    "        parameters_path = os.path.join(save_folder, \"parameters.pkl\")\n",
    "        with open(parameters_path, 'rb') as f: #reading mode for binary file\n",
    "            parameters = pickle.load(f)\n",
    "        autoencoder = VAE(*parameters) #passing parameters as positional arguments\n",
    "        weights_path = os.path.join(save_folder, \"weights.h5\")\n",
    "        autoencoder.load_weights(weights_path)\n",
    "        return autoencoder\n",
    "\n",
    "    def _calculate_combined_loss(self, y_target, y_predicted):\n",
    "        reconstruction_loss = _calculate_reconstruction_loss(y_target, y_predicted)\n",
    "        kl_loss= calculate_kl_loss(self)()\n",
    "        combined_loss = self.reconstruction_loss_weight * reconstruction_loss + kl_loss\n",
    "        return combined_loss\n",
    "\n",
    "\n",
    "    def _create_folder_if_doesnt_exist(self, save_folder):\n",
    "        if not os.path.exists(save_folder):\n",
    "            os.makedirs(save_folder)\n",
    "    \n",
    "    def _save_parameters(self, save_folder):\n",
    "        parameters = [\n",
    "            self.input_shape,\n",
    "            self.conv_filters,\n",
    "            self.conv_kernels,\n",
    "            self.conv_strides,\n",
    "            self.latent_space_dim,\n",
    "        ]\n",
    "        save_path = os.path.join(save_folder, \"parameters.pkl\")\n",
    "        with open(save_path, \"wb\") as f: #writing mode for binary file\n",
    "            pickle.dump(parameters,f)\n",
    "\n",
    "    def _save_weights(self, save_folder):\n",
    "        save_path = os.path.join(save_folder, \"weights.h5\")\n",
    "        self.model.save_weights(save_path)\n",
    "\n",
    "    def _build(self):\n",
    "        self._build_encoder()\n",
    "        self._build_decoder()\n",
    "        self._build_autoencoder()\n",
    "    \n",
    "    def _build_autoencoder(self):\n",
    "        model_input = self._model_input\n",
    "        model_output = self.decoder(self.encoder(model_input))\n",
    "        self.model = Model(model_input, model_output, name=\"autoencoder\")\n",
    "\n",
    "    def _build_decoder(self):\n",
    "        decoder_input = self._add_decoder_input()\n",
    "        dense_layer = self._add_dense_layer(decoder_input)\n",
    "        reshape_layer = self._add_reshape_layer(dense_layer)\n",
    "        conv_transpose_layers = self._add_conv_transpose_layers(reshape_layer)\n",
    "        decoder_output = self._add_decoder_output(conv_transpose_layers)\n",
    "        self.decoder = Model(decoder_input,decoder_output, name=\"decoder\") #instantiate a keras model\n",
    "\n",
    "    def _add_decoder_input(self):\n",
    "        return Input(shape=self.latent_space_dim, name=\"decoder_input\")\n",
    "\n",
    "    def _add_dense_layer(self, decoder_input):\n",
    "        num_neurons = np.prod(self._shape_before_bottleneck)\n",
    "        dense_layer = Dense(num_neurons, name=\"decoder_dense\")(decoder_input)\n",
    "        return dense_layer\n",
    "        \n",
    "    def _add_reshape_layer(self, dense_layer):\n",
    "        return Reshape(self._shape_before_bottleneck)(dense_layer)\n",
    "\n",
    "    def _add_conv_transpose_layers(self, graph_of_layers):\n",
    "        \"\"\"Add conv transpose blocks.\"\"\"\n",
    "        # Loop through all conv layers in reverse order and stop at first layer\n",
    "        for layer_index in reversed(range(1, self._num_conv_layers)):\n",
    "            # [0,1,2] -> [2,1]\n",
    "            graph_of_layers=self._add_conv_transpose_layer(layer_index, graph_of_layers)\n",
    "        return graph_of_layers\n",
    "\n",
    "    def _add_conv_transpose_layer(self, layer_index, graph_of_layers):\n",
    "        layer_number=self._num_conv_layers - layer_index\n",
    "        conv_transpose_layer = Conv2DTranspose(\n",
    "            filters=self.conv_filters[layer_index],\n",
    "            kernel_size=self.conv_kernels[layer_index],\n",
    "            strides=self.conv_strides[layer_index],\n",
    "            padding=\"same\",\n",
    "            name=f\"decoder_conv_transpose_layer_{layer_number}\"\n",
    "        )\n",
    "        graph_of_layers = conv_transpose_layer(graph_of_layers)\n",
    "        graph_of_layers = ReLU(name=f\"decoder_relu_{layer_number}\")(graph_of_layers)\n",
    "        graph_of_layers = BatchNormalization(name=f\"decode_bn_{layer_number}\")(graph_of_layers)\n",
    "        return graph_of_layers\n",
    "    \n",
    "    def _add_decoder_output(self, graph_of_layers):\n",
    "        conv_transpose_layer = Conv2DTranspose(\n",
    "            filters=1, #[24,24,1] we can interpret spectrograms as grayscale images (1 channel as output)\n",
    "            kernel_size=self.conv_kernels[0], #getting first convolutional layer in terms of kernels\n",
    "            strides=self.conv_strides[0], #getting first convolutional layer in terms of strides\n",
    "            padding=\"same\",\n",
    "            name=f\"decoder_conv_transpose_layer_{self._num_conv_layers}\" #=3\n",
    "        )\n",
    "        #apply this to incomming graph of layers\n",
    "        graph_of_layers=conv_transpose_layer(graph_of_layers)\n",
    "        output_layer= Activation(\"sigmoid\", name=\"sigmoid_layer\")(graph_of_layers) #activation layer where we use sigmoid\n",
    "        return output_layer\n",
    "\n",
    "    def _build_encoder(self):\n",
    "        encoder_input = self._add_encoder_input()\n",
    "        #building the conv layers\n",
    "        conv_layers = self._add_conv_layers(encoder_input) #sends back graph of layers\n",
    "        #build bottleneck, output to encoder\n",
    "        bottleneck = self._add_bottleneck(conv_layers)\n",
    "        self._model_input = encoder_input\n",
    "        self.encoder = Model(encoder_input,bottleneck, name=\"encoder\")\n",
    "\n",
    "\n",
    "    def _add_encoder_input(self):\n",
    "        return Input(shape=self.input_shape, name=\"encoder_input\")\n",
    "    \n",
    "    def _add_conv_layers(self, encoder_input):\n",
    "        graph_of_layers=encoder_input\n",
    "        #go step by step through all layers and add\n",
    "        for layer_index in range(self._num_conv_layers):\n",
    "            graph_of_layers=self._add_conv_layer(layer_index, graph_of_layers) #graph_of_layers will be graph of layers, conv blocks\n",
    "        return graph_of_layers\n",
    "\n",
    "    def _add_conv_layer(self, layer_index, graph_of_layers):\n",
    "        #conv 2d + ReLU + batch normalization\n",
    "        layer_number=layer_index+1\n",
    "        conv_layer= Conv2D(\n",
    "            filters=self.conv_filters[layer_index],\n",
    "            kernel_size=self.conv_kernels[layer_index],\n",
    "            strides=self.conv_strides[layer_index],\n",
    "            padding=\"same\",\n",
    "            name=f\"encoder_conv_layer_{layer_number}\"\n",
    "        )\n",
    "        graph_of_layers=conv_layer(graph_of_layers)\n",
    "        graph_of_layers = ReLU(name=f\"encoder_relu_{layer_number}\")(graph_of_layers)\n",
    "        graph_of_layers= BatchNormalization(name=f\"encoder_bn_{layer_number}\")(graph_of_layers)\n",
    "        return graph_of_layers\n",
    "    \n",
    "    def _add_bottleneck(self, graph_of_layers):\n",
    "        \"\"\"Flatten data and add bottleneck with Gaussian sampling (Dense layer).\"\"\"\n",
    "\n",
    "        self._shape_before_bottleneck= K.int_shape(graph_of_layers)[1:] #[2,7,7,32] batchsize(dont care),height width num of channels\n",
    "\n",
    "        graph_of_layers= Flatten()(graph_of_layers)\n",
    "        # graph_of_layers = Dense(self.latent_space_dim, name=\"encoder_output\")(graph_of_layers)\n",
    "        self.mu = Dense(self.latent_space_dim, name=\"mu\")(graph_of_layers)\n",
    "        self.log_variance = Dense(self.latent_space_dim, name=\"log_variance\")(graph_of_layers)\n",
    "\n",
    "        def sample_point_from_normal_distribution(args):\n",
    "            mu, log_variance = args\n",
    "            epsilon = K.random_normal(shape=K.shape(self.mu), mean=0.,stddev=1.)\n",
    "            sampled_point=mu+K.exp(log_variance/2)*epsilon\n",
    "            return sampled_point\n",
    "\n",
    "        #sample a data point from this gaussian distribution that is parametrized by this mu and log var\n",
    "        graph_of_layers = Lambda(sample_point_from_normal_distribution, name=\"encoder_output\")([self.mu,self.log_variance])\n",
    "\n",
    "        return graph_of_layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Alexandra\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py:561: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, 28, 28, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " encoder_conv_layer_1 (Conv2D)  (None, 28, 28, 32)   320         ['encoder_input[0][0]']          \n",
      "                                                                                                  \n",
      " encoder_relu_1 (ReLU)          (None, 28, 28, 32)   0           ['encoder_conv_layer_1[0][0]']   \n",
      "                                                                                                  \n",
      " encoder_bn_1 (BatchNormalizati  (None, 28, 28, 32)  128         ['encoder_relu_1[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " encoder_conv_layer_2 (Conv2D)  (None, 14, 14, 64)   18496       ['encoder_bn_1[0][0]']           \n",
      "                                                                                                  \n",
      " encoder_relu_2 (ReLU)          (None, 14, 14, 64)   0           ['encoder_conv_layer_2[0][0]']   \n",
      "                                                                                                  \n",
      " encoder_bn_2 (BatchNormalizati  (None, 14, 14, 64)  256         ['encoder_relu_2[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " encoder_conv_layer_3 (Conv2D)  (None, 7, 7, 64)     36928       ['encoder_bn_2[0][0]']           \n",
      "                                                                                                  \n",
      " encoder_relu_3 (ReLU)          (None, 7, 7, 64)     0           ['encoder_conv_layer_3[0][0]']   \n",
      "                                                                                                  \n",
      " encoder_bn_3 (BatchNormalizati  (None, 7, 7, 64)    256         ['encoder_relu_3[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " encoder_conv_layer_4 (Conv2D)  (None, 7, 7, 64)     36928       ['encoder_bn_3[0][0]']           \n",
      "                                                                                                  \n",
      " encoder_relu_4 (ReLU)          (None, 7, 7, 64)     0           ['encoder_conv_layer_4[0][0]']   \n",
      "                                                                                                  \n",
      " encoder_bn_4 (BatchNormalizati  (None, 7, 7, 64)    256         ['encoder_relu_4[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 3136)         0           ['encoder_bn_4[0][0]']           \n",
      "                                                                                                  \n",
      " mu (Dense)                     (None, 2)            6274        ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " log_variance (Dense)           (None, 2)            6274        ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " encoder_output (Lambda)        (None, 2)            0           ['mu[0][0]',                     \n",
      "                                                                  'log_variance[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 106,116\n",
      "Trainable params: 105,668\n",
      "Non-trainable params: 448\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " decoder_input (InputLayer)  [(None, 2)]               0         \n",
      "                                                                 \n",
      " decoder_dense (Dense)       (None, 3136)              9408      \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " decoder_conv_transpose_laye  (None, 7, 7, 64)         36928     \n",
      " r_1 (Conv2DTranspose)                                           \n",
      "                                                                 \n",
      " decoder_relu_1 (ReLU)       (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " decode_bn_1 (BatchNormaliza  (None, 7, 7, 64)         256       \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " decoder_conv_transpose_laye  (None, 14, 14, 64)       36928     \n",
      " r_2 (Conv2DTranspose)                                           \n",
      "                                                                 \n",
      " decoder_relu_2 (ReLU)       (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " decode_bn_2 (BatchNormaliza  (None, 14, 14, 64)       256       \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " decoder_conv_transpose_laye  (None, 28, 28, 64)       36928     \n",
      " r_3 (Conv2DTranspose)                                           \n",
      "                                                                 \n",
      " decoder_relu_3 (ReLU)       (None, 28, 28, 64)        0         \n",
      "                                                                 \n",
      " decode_bn_3 (BatchNormaliza  (None, 28, 28, 64)       256       \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " decoder_conv_transpose_laye  (None, 28, 28, 1)        577       \n",
      " r_4 (Conv2DTranspose)                                           \n",
      "                                                                 \n",
      " sigmoid_layer (Activation)  (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,537\n",
      "Trainable params: 121,153\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_input (InputLayer)  [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " encoder (Functional)        (None, 2)                 106116    \n",
      "                                                                 \n",
      " decoder (Functional)        (None, 28, 28, 1)         121537    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 227,653\n",
      "Trainable params: 226,821\n",
      "Non-trainable params: 832\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    autoencoder = VAE(\n",
    "        input_shape=(28,28,1),\n",
    "        conv_filters=(32,64,64,64),\n",
    "        conv_kernels=(3,3,3,3),\n",
    "        conv_strides=(1,2,2,1),\n",
    "        latent_space_dim=2\n",
    "    )\n",
    "    autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.11.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "1- load a file\n",
    "2- pad the signal\n",
    "3- extracting log spectrogram from signal\n",
    "4- normalize spectrogram\n",
    "5- save normalized spectrogram\n",
    "\"\"\"\n",
    "\n",
    "# import tensorflow as tf\n",
    "# import numpy as np\n",
    "# from display import display\n",
    "print(f\"Tensorflow version: {tf.__version__}\")\n",
    "\n",
    "def normalize(tensor):\n",
    "    tensor_minusmin = tensor - tensor.min()\n",
    "    tensor_maxminusmin = tensor.max() - tensor.min()\n",
    "    return tensor_minusmin / tensor_maxminusmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.11.0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ALEXAN~1\\AppData\\Local\\Temp/ipykernel_29980/2899619625.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtf_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_waves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mwaves\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_waves\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./audio_data/ENVELO01.WAV\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Alexandra\\Documents\\vae\\tf_model.py\u001b[0m in \u001b[0;36mget_waves\u001b[1;34m(file_name)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mnum_waves\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mwaves\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mwave_forms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwave_bank\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mwave_form\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwave_forms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mwave_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mwave_size\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mwave_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Alexandra\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[0mnp_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_numpy_behavior\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m       \"\"\")\n\u001b[1;32m--> 444\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "from tf_model import get_waves\n",
    "\n",
    "waves = get_waves(\"./audio_data/ENVELO01.WAV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'DecodeWav_1:0' shape=(None, None) dtype=float32>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'DecodeWav_1:1' shape=() dtype=int32>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read the raw audio from the .WAV file\n",
    "raw_audio = tf.io.read_file(filename=\"./audio_data/ENVELO01.WAV\")\n",
    "# Convert the raw audio to a waveform\n",
    "wave_bank, sample_rate = tf.audio.decode_wav(raw_audio)\n",
    "# Display the wavebank and sample_rate\n",
    "display(wave_bank, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'stack:0' shape=(64, None) dtype=float32>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wave_size = 256\n",
    "num_waves = 0\n",
    "waves = []\n",
    "\n",
    "wave_forms = tf.transpose(\n",
    "    wave_bank, perm=None, conjugate=False, name='transpose'\n",
    ")\n",
    "# display(wave_forms)\n",
    "# wave_forms = np.transpose(wave_bank.numpy())\n",
    "\n",
    "\n",
    "for i in range(64):\n",
    "    wave_form = wave_forms[0, i*wave_size:i*wave_size+wave_size]\n",
    "    # if wave_form.max() != wave_form.min():\n",
    "    #     wave_form = normalize(wave_form)\n",
    "    waves.append(wave_form)\n",
    "    num_waves += 1    \n",
    "waves = tf.stack(waves)\n",
    "display(waves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, 28, 28, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " encoder_conv_layer_1 (Conv2D)  (None, 28, 28, 32)   320         ['encoder_input[0][0]']          \n",
      "                                                                                                  \n",
      " encoder_relu_1 (ReLU)          (None, 28, 28, 32)   0           ['encoder_conv_layer_1[0][0]']   \n",
      "                                                                                                  \n",
      " encoder_bn_1 (BatchNormalizati  (None, 28, 28, 32)  128         ['encoder_relu_1[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " encoder_conv_layer_2 (Conv2D)  (None, 14, 14, 64)   18496       ['encoder_bn_1[0][0]']           \n",
      "                                                                                                  \n",
      " encoder_relu_2 (ReLU)          (None, 14, 14, 64)   0           ['encoder_conv_layer_2[0][0]']   \n",
      "                                                                                                  \n",
      " encoder_bn_2 (BatchNormalizati  (None, 14, 14, 64)  256         ['encoder_relu_2[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " encoder_conv_layer_3 (Conv2D)  (None, 7, 7, 64)     36928       ['encoder_bn_2[0][0]']           \n",
      "                                                                                                  \n",
      " encoder_relu_3 (ReLU)          (None, 7, 7, 64)     0           ['encoder_conv_layer_3[0][0]']   \n",
      "                                                                                                  \n",
      " encoder_bn_3 (BatchNormalizati  (None, 7, 7, 64)    256         ['encoder_relu_3[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " encoder_conv_layer_4 (Conv2D)  (None, 7, 7, 64)     36928       ['encoder_bn_3[0][0]']           \n",
      "                                                                                                  \n",
      " encoder_relu_4 (ReLU)          (None, 7, 7, 64)     0           ['encoder_conv_layer_4[0][0]']   \n",
      "                                                                                                  \n",
      " encoder_bn_4 (BatchNormalizati  (None, 7, 7, 64)    256         ['encoder_relu_4[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 3136)         0           ['encoder_bn_4[0][0]']           \n",
      "                                                                                                  \n",
      " mu (Dense)                     (None, 2)            6274        ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " log_variance (Dense)           (None, 2)            6274        ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " encoder_output (Lambda)        (None, 2)            0           ['mu[0][0]',                     \n",
      "                                                                  'log_variance[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 106,116\n",
      "Trainable params: 105,668\n",
      "Non-trainable params: 448\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " decoder_input (InputLayer)  [(None, 2)]               0         \n",
      "                                                                 \n",
      " decoder_dense (Dense)       (None, 3136)              9408      \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " decoder_conv_transpose_laye  (None, 7, 7, 64)         36928     \n",
      " r_1 (Conv2DTranspose)                                           \n",
      "                                                                 \n",
      " decoder_relu_1 (ReLU)       (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " decode_bn_1 (BatchNormaliza  (None, 7, 7, 64)         256       \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " decoder_conv_transpose_laye  (None, 14, 14, 64)       36928     \n",
      " r_2 (Conv2DTranspose)                                           \n",
      "                                                                 \n",
      " decoder_relu_2 (ReLU)       (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " decode_bn_2 (BatchNormaliza  (None, 14, 14, 64)       256       \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " decoder_conv_transpose_laye  (None, 28, 28, 64)       36928     \n",
      " r_3 (Conv2DTranspose)                                           \n",
      "                                                                 \n",
      " decoder_relu_3 (ReLU)       (None, 28, 28, 64)        0         \n",
      "                                                                 \n",
      " decode_bn_3 (BatchNormaliza  (None, 28, 28, 64)       256       \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " decoder_conv_transpose_laye  (None, 28, 28, 1)        577       \n",
      " r_4 (Conv2DTranspose)                                           \n",
      "                                                                 \n",
      " sigmoid_layer (Activation)  (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,537\n",
      "Trainable params: 121,153\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_input (InputLayer)  [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " encoder (Functional)        (None, 2)                 106116    \n",
      "                                                                 \n",
      " decoder (Functional)        (None, 28, 28, 1)         121537    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 227,653\n",
      "Trainable params: 226,821\n",
      "Non-trainable params: 832\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "When using data tensors as input to a model, you should specify the `steps_per_epoch` argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ALEXAN~1\\AppData\\Local\\Temp/ipykernel_29980/808389611.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;31m# x_train = load_waves(\"./audio_data/ENVELO01.WAV\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0mautoencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m     \u001b[0mautoencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;31m# autoencoder2 = Autoencoder.load(\"model\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ALEXAN~1\\AppData\\Local\\Temp/ipykernel_29980/808389611.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(x_train, learning_rate, batch_size, epochs)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mautoencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mautoencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mautoencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Alexandra\\Documents\\vae\\autoencoder.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, x_train, batch_size, num_epochs)\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;31m# input should be the same as the output in the params,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;31m# we are trying to reconstruct the output and have it as similar as possible to the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         self.model.fit(x_train, \n\u001b[0m\u001b[0;32m     64\u001b[0m                         \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m                         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Alexandra\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    853\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_select_training_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 854\u001b[1;33m         return func.fit(\n\u001b[0m\u001b[0;32m    855\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    856\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Alexandra\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training_arrays_v1.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    696\u001b[0m         )\n\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 698\u001b[1;33m         x, y, sample_weights = model._standardize_user_data(\n\u001b[0m\u001b[0;32m    699\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Alexandra\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training_v1.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2606\u001b[0m         \u001b[1;31m# Validates `steps` argument based on x's type.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2607\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_steps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2608\u001b[1;33m             \u001b[0mtraining_utils_v1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_steps_argument\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2610\u001b[0m         \u001b[1;31m# First, we build the model on the fly if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Alexandra\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training_utils_v1.py\u001b[0m in \u001b[0;36mcheck_steps_argument\u001b[1;34m(input_data, steps, steps_name)\u001b[0m\n\u001b[0;32m   1515\u001b[0m                 \u001b[1;34m\"a Dataset iterator\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mis_x_iterator\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"data tensors\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1516\u001b[0m             )\n\u001b[1;32m-> 1517\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m   1518\u001b[0m                 \u001b[1;34m\"When using {input_type} as input to a model, you should\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1519\u001b[0m                 \" specify the `{steps_name}` argument.\".format(\n",
      "\u001b[1;31mValueError\u001b[0m: When using data tensors as input to a model, you should specify the `steps_per_epoch` argument."
     ]
    }
   ],
   "source": [
    "from autoencoder import VAE\n",
    "from tensorflow import keras\n",
    "from keras.datasets import mnist\n",
    "from preprocess import get_waves\n",
    "\n",
    "LEARNING_RATE=0.0005\n",
    "BATCH_SIZE=32\n",
    "EPOCHS=20\n",
    "\n",
    "# def load_mnist():\n",
    "#     (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "#     x_train = x_train.astype(\"float32\") / 255\n",
    "#     x_train = x_train.reshape(x_train.shape + (1,))\n",
    "\n",
    "#     x_test = x_test.astype(\"float32\") / 255\n",
    "#     x_test = x_test.reshape(x_test.shape + (1,))\n",
    "\n",
    "#     return x_train, y_train, x_test, y_test\n",
    "\n",
    "def load_waves(file):\n",
    "    train_dataset = get_waves(file)    \n",
    "    return train_dataset\n",
    "\n",
    "\n",
    "def train(x_train, learning_rate, batch_size, epochs):\n",
    "    autoencoder = VAE(\n",
    "        input_shape=(28,28,1),\n",
    "        conv_filters=(32,64,64,64),\n",
    "        conv_kernels=(3,3,3,3),\n",
    "        conv_strides=(1,2,2,1),\n",
    "        latent_space_dim=2 #reducing down all of the complexity of the original data to only 2 dimensions\n",
    "    )\n",
    "    autoencoder.summary()\n",
    "    autoencoder.compile(learning_rate)\n",
    "    autoencoder.train(x_train, batch_size,epochs)\n",
    "    \n",
    "    return autoencoder\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # x_train, _, _, _ = load_mnist()\n",
    "    # x_train = load_waves(\"./audio_data/ENVELO01.WAV\")\n",
    "    x_train = waves\n",
    "    autoencoder = train(x_train[:50], LEARNING_RATE, BATCH_SIZE, EPOCHS)\n",
    "    autoencoder.save(\"model\")\n",
    "    # autoencoder2 = Autoencoder.load(\"model\")\n",
    "    # autoencoder2.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "610c699f0cd8c4f129acd9140687fff6866bed0eb8e82f249fc8848b827b628c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
