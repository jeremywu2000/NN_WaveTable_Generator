{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Tensorflow v2.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Conv2DTranspose, Reshape, Dense\n",
    "from keras import Model\n",
    "import numpy as np\n",
    "print(f\"Using Tensorflow v{tf.__version__}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Encoder_Conv2D_1 (Conv2D)   (None, 1, 128, 16)        80        \n",
      "                                                                 \n",
      " Encoder_Conv2D_2 (Conv2D)   (None, 1, 64, 32)         2080      \n",
      "                                                                 \n",
      " Encoder_Reshape (Reshape)   (None, 1, 2048)           0         \n",
      "                                                                 \n",
      " Encoder_Dense_1 (Dense)     (None, 1, 16)             32784     \n",
      "                                                                 \n",
      " Encoder_Dense_2 (Dense)     (None, 1, 16)             272       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35,216\n",
      "Trainable params: 35,216\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder = Sequential(name=\"Encoder\")\n",
    "encoder.add(Conv2D(16, kernel_size=(4,1), strides=(1,2), padding='same', activation='relu', input_shape=(1,256,1), name=\"Encoder_Conv2D_1\"))\n",
    "encoder.add(Conv2D(32, kernel_size=(4,1), strides=(1,2), padding='same', activation='relu', name=\"Encoder_Conv2D_2\"))\n",
    "encoder.add(Reshape((1,-1), name=\"Encoder_Reshape\"))\n",
    "encoder.add(Dense(16, name=\"Encoder_Dense_1\"))\n",
    "encoder.add(Dense(16, name=\"Encoder_Dense_2\"))\n",
    "\n",
    "encoder.build()\n",
    "encoder.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Decoder_Dense (Dense)       (None, 1, 16, 128)        256       \n",
      "                                                                 \n",
      " Decoder_Reshape (Reshape)   (None, 1, 64, 32)         0         \n",
      "                                                                 \n",
      " Decoder_Conv2D_T_1 (Conv2DT  (None, 1, 128, 16)       2064      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " Decoder_Conv2D_T_2 (Conv2DT  (None, 1, 256, 1)        65        \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,385\n",
      "Trainable params: 2,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder = tf.keras.models.Sequential(name=\"Decoder\")\n",
    "decoder.add(tf.keras.layers.Dense(128, input_shape=(1,16,1), name=\"Decoder_Dense\"))\n",
    "decoder.add(tf.keras.layers.Reshape((1,64,-1), name=\"Decoder_Reshape\"))\n",
    "decoder.add(tf.keras.layers.Conv2DTranspose(16, kernel_size=(4,1),strides=(1,2), padding='same', activation='relu', name=\"Decoder_Conv2D_T_1\"))\n",
    "decoder.add(tf.keras.layers.Conv2DTranspose(1, kernel_size=(4,1),strides=(1,2), padding='same', activation='sigmoid', name=\"Decoder_Conv2D_T_2\"))\n",
    "\n",
    "decoder.build()\n",
    "decoder.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.recon_loss_tracker = keras.metrics.Mean(name=\"recon_loss\")\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.recon_loss_tracker\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            recon_results = self.decoder(self.encoder(data))\n",
    "            recon_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data, recon_results)\n",
    "                )\n",
    "            )\n",
    "        grads = tape.gradient(recon_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.recon_loss_tracker.update_state(recon_loss)\n",
    "        return {\n",
    "            \"recon_loss\": self.recon_loss_tracker.result()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(tensor):\n",
    "    tensor_minusmin = tensor - tensor.min()\n",
    "    tensor_maxminusmin = tensor.max() - tensor.min()\n",
    "    return tensor_minusmin / tensor_maxminusmin\n",
    "\n",
    "def get_waves(file_name):\n",
    "    # Read the raw audio from the .WAV file\n",
    "    raw_audio = tf.io.read_file(filename=file_name)\n",
    "    # Convert the raw audio to a waveform\n",
    "    wave_bank, sample_rate = tf.audio.decode_wav(raw_audio)\n",
    "    # Display the wavebank and sample_rate\n",
    "    # display(wave_bank, sample_rate)\n",
    "    wave_size = 256\n",
    "    num_waves = 0\n",
    "    waves = []\n",
    "    wave_forms = np.transpose(wave_bank.numpy())\n",
    "    for i in range(64):\n",
    "        wave_form = wave_forms[0, i*wave_size:i*wave_size+wave_size]\n",
    "        if wave_form.max() != wave_form.min():\n",
    "            wave_form = normalize(wave_form)\n",
    "            waves.append(wave_form)\n",
    "            num_waves += 1    \n",
    "    waves = tf.stack(waves)\n",
    "    return waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 256])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 1, 1, 256, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "waves = get_waves(\"./audio_data/ENVELO01.WAV\")\n",
    "display(waves.shape)\n",
    "waves = tf.expand_dims(waves,1)\n",
    "waves = tf.expand_dims(waves,1)\n",
    "waves = tf.expand_dims(waves,-1)\n",
    "display(waves.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Autoencoder(encoder=encoder, decoder=decoder)\n",
    "autoencoder.compile(optimizer=keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 16), dtype=float32, numpy=\n",
       "array([[[-0.01558048,  0.0111496 ,  0.01787113, -0.04636577,\n",
       "         -0.00938693, -0.01669247, -0.00726766, -0.02033841,\n",
       "         -0.02910567,  0.03464256, -0.02980057, -0.01850165,\n",
       "         -0.03295462, -0.05090476,  0.03763466,  0.00575553]]],\n",
       "      dtype=float32)>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(encoder(waves[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    for i in waves:\n",
    "        recon_loss = autoencoder.train_step(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff1ec9c71d6c6569ddb6931262fd540c04a3bd4bd27a165637ca0df5de8b220f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
